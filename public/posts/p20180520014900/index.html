<!DOCTYPE html>
<html lang="en-us" dir="ltr">
<head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
  



  
  


<head lang="en-us">
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  <meta name="HandheldFriendly" content="True" />
  <meta name="MobileOptimized" content="320" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="color-scheme" content="dark light">
  <meta name="description" content="浅谈高维数据可视化中的降维方法
来源：[link]: https://blog.csdn.net/u011001084/article/details/51396447
我们生活在三维空间中，很难直接理解三维以上的空间（爱因斯坦等牛人除外）。但是爱因斯坦这样的人毕竟在人群中是少数，对大多数人来说，高维数据如何进行可视化呢？
聪明的人可以用其他的视觉通道对一些维度进行视觉编码，比如颜色、形状、朝向、体积、半径、表面覆盖物等等。。。不过有两个很显然的问题，1）用户理解起来，不那么方便了。可能要想半天才能反应过来，因为要对这些视觉通道进行一一的反编码，记住这些本身就挺难的。2）维度比较大，不多说，就十几维，恐怕视觉通道已经捉襟见肘，不够用了。
那咋办呢？目前，对高维数据进行可视化主要有三大类方法。

得益于机器学习的发展，降维的方法越来越多。把维度降到2或者3，就可以用非常传统的散点图来将结果进行可视化了。但是降维带来的问题也是显然的，降维的初衷是将原始维度中冗余无用的信息滤掉，不过这个过程很可能不能避免的将有用的信息也丢失掉了。
为了避免上面的问题，第二类方法决定不降维了，直接用散点矩阵把维度直接的两两关系全部展现出来，，这样用户就可以很清楚的看到维度之间的两两关系了嘛。但是你很快就头疼了，10维的散点矩阵，足足有100个小的散点图，这可咋看呀！
第三种方法呢，是想不降维，但同时也不希望出现太多的图让用户去看，最好就一张图。典型的代表方法有平行坐标轴、RadViz、Star coordinates等，以及最近华人学者曹楠老师提出来的UnTangle Map【1】，感兴趣的可以看后面列出来的参考文献。
这篇博客主要介绍第一类方法，降维。线性和非线性各选两三种有代表性的方法讲述。降维方法的分类见下图：

线性降维方法
PCA
可能大部分人接触的第一个降维方法都是PCA，PCA是一种线性的降维方法，举一个二维特征的例子，见下图。这两个特征之间存在着很明显的线性关系，检测出这些线性关系，并且去除它是PCA的目标。具体到下面的这个图，如果我们把x1,x2坐标系换成u1，u2 ，可以看到u1反应了特征的主要变化，而u2的变化比较小，几乎可以忽略不计，那么就可以用u1一个维度代表x1，x2 两个维度，也就达到了降维的目的。
我承认，目前比较火的图像、视频、文字等多媒体数据大多是在一个非线性的流形上或者附近，PCA作为一种线性的降维方法可能不太使用了。但是PCA依然是不可替代的，比如去年IEEE Vis年会中的可视分析（VAST2015）最佳论文就颁给了一个使用PCA来做动态网络分析的工作【2】。
LDA
与PCA保持数据信息不同，LDA是为了使得降维后的数据点尽可能地容易被区分。既然是线性的，那么就是希望找到映射向量a， 使得 a‘X后的数据点能够保持以下两种性质：
同类数据点尽可能接近
不同类数据点尽可能分开
为了显示与PCA的区别，在网上找来了下面的图，PCA找到的是轴2，LDA找到的是轴1. LDA与PCA的目标不同，LDA希望降维后数据可以很容易的被分开。
近期也看了一篇Pacific Visualization 2016里利用LDA进行高维子空间的维度重建相关工作的论文【3】。
非线性降维方法
MDS
MDS中文名叫多维尺度分析，主要考虑的是成对样本间的相似性，主要思想是用成对样本的相似性来构建合适的低维空间，使得样本在低维空间的距离和高位空间中的距离尽可能的保持一致。非常合理但是有很对的思想。根据样本是否可计量，可分为Metric MDS和Nonmetric MDS。目标函数是每对低维空间中的欧式距离与高维空间中相似度差的平方和，最小化目标函数，用一些数值优化方法来得到最优解。
Isomap
Isomap的理论框架是MDS，但是高维空间中的距离变了，不再是欧式距离了，而是用测地线距离代替了欧式距离。所谓的测地线，就是流形上加速度为零的曲线，等同于欧式空间中的直线。如下图所示，s曲面上蓝色和红色的两点，欧式距离很小，而实际上他们之间没有路，因此必须沿着曲面走完测地线，所以他们之间的距离很大。
SNE &amp; t-SNE
这两种方法是Hinton组【4】提出的，可以说是state-of-art的方法。SNE想法与MDS类似，也是想将高维空间中的邻居信息保存到低维空间中，不过SNE的心比较小，它不是将所有点对直接的距离都保存下来，它只想将跟附近的邻居在一起，其他的离他本来就很远的点，根本不care。他的做法是将高维空间中点与点之间的欧式距离转化成条件概率，来代表相似度。低维空间中，也同样计算出这样一个概率。现在有了两个概率分布，怎么衡量他们之间的相似度呢？用KL散度！
KL散度是不平衡的，KL(p||q)与KL(q||p)不相对，这意味着不同种类的点对之间的距离错误在低维空间中没有得到同等对待。因此，symmetric SNE被提出来了。
t-SNE对于SNE改进是将高维空间中的欧氏距离换成了高斯分布，低维空间中，使用了heavy-tailed student t-distribution。带来了两个优点：
t-SNE的梯度强烈抵制不相似的点对在低维空间中被建模成距离很近。
尽管引入了不相似点对之间强烈的排斥，排斥力不会走向无穷。
t-SNE主要包括两个步骤：第一、t-SNE构建一个高维对象之间的概率分布，使得相似的对象有更高的概率被选择，而不相似的对象有较低的概率被选择。第二，t-SNE在低维空间里在构建这些点的概率分布，使得这两个概率分布之间尽可能的相似，同样也是来度量两个分布之间的相似性。
t-SNE可以将MNIST手写数字集几乎完全分开。在线尝试：http://scienceai.github.io/tsne-js/
t-SNE哪里都好，但是有一个致命的弱点，就是慢。不过，近期刚结束的WWW 2016上，华人学者唐健提出的LargeViz【5】，速度比t-SNE快了近30倍，想法很好！这种好的工作，比改改深度学习中网络的结构，调调参数，水一百篇论文更有意义！
参考文献
【1】Nan Cao, Yu-Ru Lin, and David Gotz
，UnTangle Map: Visual Analysis of Probabilistic Multi-Label Data ，IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS, VOL. 22, NO. 2, FEBRUARY 2016" />
  <meta name="author" content="Hugo Author">
  <meta name="keywords" content="">
  <title>浅谈高维数据可视化中的降维方法 | Combine Art and Sciences</title>
  <link rel="canonical" href="http://localhost:1313/posts/p20180520014900/" />
  

  
  <meta property="og:type" content="article" />
  <meta property="og:description" content="浅谈高维数据可视化中的降维方法
来源：[link]: https://blog.csdn.net/u011001084/article/details/51396447
我们生活在三维空间中，很难直接理解三维以上的空间（爱因斯坦等牛人除外）。但是爱因斯坦这样的人毕竟在人群中是少数，对大多数人来说，高维数据如何进行可视化呢？
聪明的人可以用其他的视觉通道对一些维度进行视觉编码，比如颜色、形状、朝向、体积、半径、表面覆盖物等等。。。不过有两个很显然的问题，1）用户理解起来，不那么方便了。可能要想半天才能反应过来，因为要对这些视觉通道进行一一的反编码，记住这些本身就挺难的。2）维度比较大，不多说，就十几维，恐怕视觉通道已经捉襟见肘，不够用了。
那咋办呢？目前，对高维数据进行可视化主要有三大类方法。

得益于机器学习的发展，降维的方法越来越多。把维度降到2或者3，就可以用非常传统的散点图来将结果进行可视化了。但是降维带来的问题也是显然的，降维的初衷是将原始维度中冗余无用的信息滤掉，不过这个过程很可能不能避免的将有用的信息也丢失掉了。
为了避免上面的问题，第二类方法决定不降维了，直接用散点矩阵把维度直接的两两关系全部展现出来，，这样用户就可以很清楚的看到维度之间的两两关系了嘛。但是你很快就头疼了，10维的散点矩阵，足足有100个小的散点图，这可咋看呀！
第三种方法呢，是想不降维，但同时也不希望出现太多的图让用户去看，最好就一张图。典型的代表方法有平行坐标轴、RadViz、Star coordinates等，以及最近华人学者曹楠老师提出来的UnTangle Map【1】，感兴趣的可以看后面列出来的参考文献。
这篇博客主要介绍第一类方法，降维。线性和非线性各选两三种有代表性的方法讲述。降维方法的分类见下图：

线性降维方法
PCA
可能大部分人接触的第一个降维方法都是PCA，PCA是一种线性的降维方法，举一个二维特征的例子，见下图。这两个特征之间存在着很明显的线性关系，检测出这些线性关系，并且去除它是PCA的目标。具体到下面的这个图，如果我们把x1,x2坐标系换成u1，u2 ，可以看到u1反应了特征的主要变化，而u2的变化比较小，几乎可以忽略不计，那么就可以用u1一个维度代表x1，x2 两个维度，也就达到了降维的目的。
我承认，目前比较火的图像、视频、文字等多媒体数据大多是在一个非线性的流形上或者附近，PCA作为一种线性的降维方法可能不太使用了。但是PCA依然是不可替代的，比如去年IEEE Vis年会中的可视分析（VAST2015）最佳论文就颁给了一个使用PCA来做动态网络分析的工作【2】。
LDA
与PCA保持数据信息不同，LDA是为了使得降维后的数据点尽可能地容易被区分。既然是线性的，那么就是希望找到映射向量a， 使得 a‘X后的数据点能够保持以下两种性质：
同类数据点尽可能接近
不同类数据点尽可能分开
为了显示与PCA的区别，在网上找来了下面的图，PCA找到的是轴2，LDA找到的是轴1. LDA与PCA的目标不同，LDA希望降维后数据可以很容易的被分开。
近期也看了一篇Pacific Visualization 2016里利用LDA进行高维子空间的维度重建相关工作的论文【3】。
非线性降维方法
MDS
MDS中文名叫多维尺度分析，主要考虑的是成对样本间的相似性，主要思想是用成对样本的相似性来构建合适的低维空间，使得样本在低维空间的距离和高位空间中的距离尽可能的保持一致。非常合理但是有很对的思想。根据样本是否可计量，可分为Metric MDS和Nonmetric MDS。目标函数是每对低维空间中的欧式距离与高维空间中相似度差的平方和，最小化目标函数，用一些数值优化方法来得到最优解。
Isomap
Isomap的理论框架是MDS，但是高维空间中的距离变了，不再是欧式距离了，而是用测地线距离代替了欧式距离。所谓的测地线，就是流形上加速度为零的曲线，等同于欧式空间中的直线。如下图所示，s曲面上蓝色和红色的两点，欧式距离很小，而实际上他们之间没有路，因此必须沿着曲面走完测地线，所以他们之间的距离很大。
SNE &amp; t-SNE
这两种方法是Hinton组【4】提出的，可以说是state-of-art的方法。SNE想法与MDS类似，也是想将高维空间中的邻居信息保存到低维空间中，不过SNE的心比较小，它不是将所有点对直接的距离都保存下来，它只想将跟附近的邻居在一起，其他的离他本来就很远的点，根本不care。他的做法是将高维空间中点与点之间的欧式距离转化成条件概率，来代表相似度。低维空间中，也同样计算出这样一个概率。现在有了两个概率分布，怎么衡量他们之间的相似度呢？用KL散度！
KL散度是不平衡的，KL(p||q)与KL(q||p)不相对，这意味着不同种类的点对之间的距离错误在低维空间中没有得到同等对待。因此，symmetric SNE被提出来了。
t-SNE对于SNE改进是将高维空间中的欧氏距离换成了高斯分布，低维空间中，使用了heavy-tailed student t-distribution。带来了两个优点：
t-SNE的梯度强烈抵制不相似的点对在低维空间中被建模成距离很近。
尽管引入了不相似点对之间强烈的排斥，排斥力不会走向无穷。
t-SNE主要包括两个步骤：第一、t-SNE构建一个高维对象之间的概率分布，使得相似的对象有更高的概率被选择，而不相似的对象有较低的概率被选择。第二，t-SNE在低维空间里在构建这些点的概率分布，使得这两个概率分布之间尽可能的相似，同样也是来度量两个分布之间的相似性。
t-SNE可以将MNIST手写数字集几乎完全分开。在线尝试：http://scienceai.github.io/tsne-js/
t-SNE哪里都好，但是有一个致命的弱点，就是慢。不过，近期刚结束的WWW 2016上，华人学者唐健提出的LargeViz【5】，速度比t-SNE快了近30倍，想法很好！这种好的工作，比改改深度学习中网络的结构，调调参数，水一百篇论文更有意义！
参考文献
【1】Nan Cao, Yu-Ru Lin, and David Gotz
，UnTangle Map: Visual Analysis of Probabilistic Multi-Label Data ，IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS, VOL. 22, NO. 2, FEBRUARY 2016" />
  <meta property="og:title" content="浅谈高维数据可视化中的降维方法" />
  <meta property="og:site_name" content="Combine Art and Sciences" />
  <meta property="og:image:type" content="image/jpeg" />
  <meta property="og:url" content="http://localhost:1313/posts/p20180520014900/" />
  <meta property="og:locale" content="en-us" />

  
    <meta property="article:published_time" content="2018-05-20" />
    <meta property="article:modified_time" content="2018-05-20" />
    
  

  
  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="浅谈高维数据可视化中的降维方法 | Combine Art and Sciences" />
  <meta name="twitter:description" content="浅谈高维数据可视化中的降维方法
来源：[link]: https://blog.csdn.net/u011001084/article/details/51396447
我们生活在三维空间中，很难直接理解三维以上的空间（爱因斯坦等牛人除外）。但是爱因斯坦这样的人毕竟在人群中是少数，对大多数人来说，高维数据如何进行可视化呢？
聪明的人可以用其他的视觉通道对一些维度进行视觉编码，比如颜色、形状、朝向、体积、半径、表面覆盖物等等。。。不过有两个很显然的问题，1）用户理解起来，不那么方便了。可能要想半天才能反应过来，因为要对这些视觉通道进行一一的反编码，记住这些本身就挺难的。2）维度比较大，不多说，就十几维，恐怕视觉通道已经捉襟见肘，不够用了。
那咋办呢？目前，对高维数据进行可视化主要有三大类方法。

得益于机器学习的发展，降维的方法越来越多。把维度降到2或者3，就可以用非常传统的散点图来将结果进行可视化了。但是降维带来的问题也是显然的，降维的初衷是将原始维度中冗余无用的信息滤掉，不过这个过程很可能不能避免的将有用的信息也丢失掉了。
为了避免上面的问题，第二类方法决定不降维了，直接用散点矩阵把维度直接的两两关系全部展现出来，，这样用户就可以很清楚的看到维度之间的两两关系了嘛。但是你很快就头疼了，10维的散点矩阵，足足有100个小的散点图，这可咋看呀！
第三种方法呢，是想不降维，但同时也不希望出现太多的图让用户去看，最好就一张图。典型的代表方法有平行坐标轴、RadViz、Star coordinates等，以及最近华人学者曹楠老师提出来的UnTangle Map【1】，感兴趣的可以看后面列出来的参考文献。
这篇博客主要介绍第一类方法，降维。线性和非线性各选两三种有代表性的方法讲述。降维方法的分类见下图：

线性降维方法
PCA
可能大部分人接触的第一个降维方法都是PCA，PCA是一种线性的降维方法，举一个二维特征的例子，见下图。这两个特征之间存在着很明显的线性关系，检测出这些线性关系，并且去除它是PCA的目标。具体到下面的这个图，如果我们把x1,x2坐标系换成u1，u2 ，可以看到u1反应了特征的主要变化，而u2的变化比较小，几乎可以忽略不计，那么就可以用u1一个维度代表x1，x2 两个维度，也就达到了降维的目的。
我承认，目前比较火的图像、视频、文字等多媒体数据大多是在一个非线性的流形上或者附近，PCA作为一种线性的降维方法可能不太使用了。但是PCA依然是不可替代的，比如去年IEEE Vis年会中的可视分析（VAST2015）最佳论文就颁给了一个使用PCA来做动态网络分析的工作【2】。
LDA
与PCA保持数据信息不同，LDA是为了使得降维后的数据点尽可能地容易被区分。既然是线性的，那么就是希望找到映射向量a， 使得 a‘X后的数据点能够保持以下两种性质：
同类数据点尽可能接近
不同类数据点尽可能分开
为了显示与PCA的区别，在网上找来了下面的图，PCA找到的是轴2，LDA找到的是轴1. LDA与PCA的目标不同，LDA希望降维后数据可以很容易的被分开。
近期也看了一篇Pacific Visualization 2016里利用LDA进行高维子空间的维度重建相关工作的论文【3】。
非线性降维方法
MDS
MDS中文名叫多维尺度分析，主要考虑的是成对样本间的相似性，主要思想是用成对样本的相似性来构建合适的低维空间，使得样本在低维空间的距离和高位空间中的距离尽可能的保持一致。非常合理但是有很对的思想。根据样本是否可计量，可分为Metric MDS和Nonmetric MDS。目标函数是每对低维空间中的欧式距离与高维空间中相似度差的平方和，最小化目标函数，用一些数值优化方法来得到最优解。
Isomap
Isomap的理论框架是MDS，但是高维空间中的距离变了，不再是欧式距离了，而是用测地线距离代替了欧式距离。所谓的测地线，就是流形上加速度为零的曲线，等同于欧式空间中的直线。如下图所示，s曲面上蓝色和红色的两点，欧式距离很小，而实际上他们之间没有路，因此必须沿着曲面走完测地线，所以他们之间的距离很大。
SNE &amp; t-SNE
这两种方法是Hinton组【4】提出的，可以说是state-of-art的方法。SNE想法与MDS类似，也是想将高维空间中的邻居信息保存到低维空间中，不过SNE的心比较小，它不是将所有点对直接的距离都保存下来，它只想将跟附近的邻居在一起，其他的离他本来就很远的点，根本不care。他的做法是将高维空间中点与点之间的欧式距离转化成条件概率，来代表相似度。低维空间中，也同样计算出这样一个概率。现在有了两个概率分布，怎么衡量他们之间的相似度呢？用KL散度！
KL散度是不平衡的，KL(p||q)与KL(q||p)不相对，这意味着不同种类的点对之间的距离错误在低维空间中没有得到同等对待。因此，symmetric SNE被提出来了。
t-SNE对于SNE改进是将高维空间中的欧氏距离换成了高斯分布，低维空间中，使用了heavy-tailed student t-distribution。带来了两个优点：
t-SNE的梯度强烈抵制不相似的点对在低维空间中被建模成距离很近。
尽管引入了不相似点对之间强烈的排斥，排斥力不会走向无穷。
t-SNE主要包括两个步骤：第一、t-SNE构建一个高维对象之间的概率分布，使得相似的对象有更高的概率被选择，而不相似的对象有较低的概率被选择。第二，t-SNE在低维空间里在构建这些点的概率分布，使得这两个概率分布之间尽可能的相似，同样也是来度量两个分布之间的相似性。
t-SNE可以将MNIST手写数字集几乎完全分开。在线尝试：http://scienceai.github.io/tsne-js/
t-SNE哪里都好，但是有一个致命的弱点，就是慢。不过，近期刚结束的WWW 2016上，华人学者唐健提出的LargeViz【5】，速度比t-SNE快了近30倍，想法很好！这种好的工作，比改改深度学习中网络的结构，调调参数，水一百篇论文更有意义！
参考文献
【1】Nan Cao, Yu-Ru Lin, and David Gotz
，UnTangle Map: Visual Analysis of Probabilistic Multi-Label Data ，IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS, VOL. 22, NO. 2, FEBRUARY 2016" />
  <meta name="twitter:domain" content="http://localhost:1313/posts/p20180520014900/" />

  
  
    <link rel="icon" href="http://localhost:1313/favicon.ico">
  
  
  
  

  
  <link rel="stylesheet" href="//cdn.jsdelivr.net/npm/modern-normalize/modern-normalize.min.css">

  
  
  

  

  
    <link rel="stylesheet" href="http://localhost:1313/style.css" rel="preload stylesheet" as="style"/>
  

  
  
</head>

</head>
<body>
  <header>
    <header id="header">
  <div class="row">
    <div class="container has-padding nav">
      <button id="navbar-toggler" class="navbar-button" aria-hidden="true">











<svg xmlns='http://www.w3.org/2000/svg' class='ionicon' viewBox='0 0 512 512'><path d='M64 384h384v-42.67H64zm0-106.67h384v-42.66H64zM64 128v42.67h384V128z'/></svg>





</button>
      <div class="navbar-brand">
        <a class="logo navbar-button" href="http://localhost:1313/" title="Combine Art and Sciences">
          <span>Combine Art and Sciences</span>
        </a>
      </div>
      <nav class="navbar" role="navigation">
        <ul>
          
          
            <li class="nav-bar-item active">
              <a class="nav-link navbar-button" href="/posts/" title="posts">
                <span>posts</span>
              </a>
            </li>
          
            <li class="nav-bar-item">
              <a class="nav-link navbar-button" href="/tags/" title="tags">
                <span>tags</span>
              </a>
            </li>
          
            <li class="nav-bar-item">
              <a class="nav-link navbar-button" href="/archives/" title="archives">
                <span>archives</span>
              </a>
            </li>
          
            <li class="nav-bar-item">
              <a class="nav-link navbar-button" href="/about/" title="about">
                <span>about</span>
              </a>
            </li>
          
        </ul>
      </nav>
      <div class="theme-selector">
        <button class="button is-text" id="theme-selector-button" title="toggle theme">
          <span class="label icon">





<svg xmlns='http://www.w3.org/2000/svg' class='ionicon' viewBox='0 0 512 512'><path d='M256 32C132.29 32 32 132.29 32 256s100.29 224 224 224 224-100.29 224-224S379.71 32 256 32zM128.72 383.28A180 180 0 01256 76v360a178.82 178.82 0 01-127.28-52.72z'/></svg>











</span>
        </button>
      </div>
    </div>
    
      <div class="container has-padding">
        <div class="breadcrumb">
          
<ol  class="breadcrumb-nav">
  

  

  

<li >
  <a href="http://localhost:1313/">Home</a>
</li>


<li >
  <a href="http://localhost:1313/posts/">Posts</a>
</li>


<li class="active">
  <a href="http://localhost:1313/posts/p20180520014900/">浅谈高维数据可视化中的降维方法</a>
</li>

</ol>




        </div>
      </div>
    
  </div>
</header>

  </header>
  <main>
    

<main id="main">
  <div class="container has-padding">
    <div class="article-card post single">
      <h1 class="title">浅谈高维数据可视化中的降维方法</h1>
      <div class="post-info">
        <span>



<svg xmlns='http://www.w3.org/2000/svg' class='ionicon' viewBox='0 0 512 512'><path d='M32 456a24 24 0 0024 24h400a24 24 0 0024-24V176H32zm320-244a4 4 0 014-4h40a4 4 0 014 4v40a4 4 0 01-4 4h-40a4 4 0 01-4-4zm0 80a4 4 0 014-4h40a4 4 0 014 4v40a4 4 0 01-4 4h-40a4 4 0 01-4-4zm-80-80a4 4 0 014-4h40a4 4 0 014 4v40a4 4 0 01-4 4h-40a4 4 0 01-4-4zm0 80a4 4 0 014-4h40a4 4 0 014 4v40a4 4 0 01-4 4h-40a4 4 0 01-4-4zm0 80a4 4 0 014-4h40a4 4 0 014 4v40a4 4 0 01-4 4h-40a4 4 0 01-4-4zm-80-80a4 4 0 014-4h40a4 4 0 014 4v40a4 4 0 01-4 4h-40a4 4 0 01-4-4zm0 80a4 4 0 014-4h40a4 4 0 014 4v40a4 4 0 01-4 4h-40a4 4 0 01-4-4zm-80-80a4 4 0 014-4h40a4 4 0 014 4v40a4 4 0 01-4 4h-40a4 4 0 01-4-4zm0 80a4 4 0 014-4h40a4 4 0 014 4v40a4 4 0 01-4 4h-40a4 4 0 01-4-4zM456 64h-55.92V32h-48v32H159.92V32h-48v32H56a23.8 23.8 0 00-24 23.77V144h448V87.77A23.8 23.8 0 00456 64z'/></svg>













<time datetime=2018-05-20T01:49:00&#43;0800 class="date">May 20, 2018</time></span>
        <span>
















<svg xmlns='http://www.w3.org/2000/svg' class='ionicon' viewBox='0 0 512 512'><path d='M256 48C141.13 48 48 141.13 48 256c0 114.69 93.32 208 208 208 114.86 0 208-93.14 208-208 0-114.69-93.31-208-208-208zm108 240H244a4 4 0 01-4-4V116a4 4 0 014-4h24a4 4 0 014 4v140h92a4 4 0 014 4v24a4 4 0 01-4 4z'/></svg>
a min to read</span>
        
          <span>












<svg xmlns='http://www.w3.org/2000/svg' class='ionicon' viewBox='0 0 512 512'><path d='M256 256a112 112 0 10-112-112 112 112 0 00112 112zm0 32c-69.42 0-208 42.88-208 128v64h416v-64c0-85.12-138.58-128-208-128z'/></svg>




Hugo Author</span>
        
        
        
          <span>posts </span>
        
      </div>
      <article class="post-entry content">
        
          <h1 id="浅谈高维数据可视化中的降维方法">浅谈高维数据可视化中的降维方法<a hidden class="heading-anchor" aria-hidden="true" href="#浅谈高维数据可视化中的降维方法">#</a></h1>
<p>来源：[link]: <a href="https://blog.csdn.net/u011001084/article/details/51396447">https://blog.csdn.net/u011001084/article/details/51396447</a></p>
<p>我们生活在三维空间中，很难直接理解三维以上的空间（爱因斯坦等牛人除外）。但是爱因斯坦这样的人毕竟在人群中是少数，对大多数人来说，高维数据如何进行可视化呢？</p>
<p>聪明的人可以用其他的视觉通道对一些维度进行视觉编码，比如颜色、形状、朝向、体积、半径、表面覆盖物等等。。。不过有两个很显然的问题，1）用户理解起来，不那么方便了。可能要想半天才能反应过来，因为要对这些视觉通道进行一一的反编码，记住这些本身就挺难的。2）维度比较大，不多说，就十几维，恐怕视觉通道已经捉襟见肘，不够用了。</p>
<p>那咋办呢？目前，对高维数据进行可视化主要有三大类方法。</p>
<ol>
<li>得益于机器学习的发展，降维的方法越来越多。把维度降到2或者3，就可以用非常传统的散点图来将结果进行可视化了。但是降维带来的问题也是显然的，降维的初衷是将原始维度中冗余无用的信息滤掉，不过这个过程很可能不能避免的将有用的信息也丢失掉了。</li>
<li>为了避免上面的问题，第二类方法决定不降维了，直接用散点矩阵把维度直接的两两关系全部展现出来，，这样用户就可以很清楚的看到维度之间的两两关系了嘛。但是你很快就头疼了，10维的散点矩阵，足足有100个小的散点图，这可咋看呀！</li>
<li>第三种方法呢，是想不降维，但同时也不希望出现太多的图让用户去看，最好就一张图。典型的代表方法有平行坐标轴、RadViz、Star coordinates等，以及最近华人学者曹楠老师提出来的UnTangle Map【1】，感兴趣的可以看后面列出来的参考文献。
这篇博客主要介绍第一类方法，降维。线性和非线性各选两三种有代表性的方法讲述。降维方法的分类见下图：</li>
</ol>
<h2 id="线性降维方法">线性降维方法<a hidden class="heading-anchor" aria-hidden="true" href="#线性降维方法">#</a></h2>
<h3 id="pca">PCA<a hidden class="heading-anchor" aria-hidden="true" href="#pca">#</a></h3>
<p>可能大部分人接触的第一个降维方法都是PCA，PCA是一种线性的降维方法，举一个二维特征的例子，见下图。这两个特征之间存在着很明显的线性关系，检测出这些线性关系，并且去除它是PCA的目标。具体到下面的这个图，如果我们把x1,x2坐标系换成u1，u2 ，可以看到u1反应了特征的主要变化，而u2的变化比较小，几乎可以忽略不计，那么就可以用u1一个维度代表x1，x2 两个维度，也就达到了降维的目的。</p>
<p>我承认，目前比较火的图像、视频、文字等多媒体数据大多是在一个非线性的流形上或者附近，PCA作为一种线性的降维方法可能不太使用了。但是PCA依然是不可替代的，比如去年IEEE Vis年会中的可视分析（VAST2015）最佳论文就颁给了一个使用PCA来做动态网络分析的工作【2】。</p>
<h3 id="lda">LDA<a hidden class="heading-anchor" aria-hidden="true" href="#lda">#</a></h3>
<p>与PCA保持数据信息不同，LDA是为了使得降维后的数据点尽可能地容易被区分。既然是线性的，那么就是希望找到映射向量a， 使得 a‘X后的数据点能够保持以下两种性质：</p>
<p>同类数据点尽可能接近
不同类数据点尽可能分开
为了显示与PCA的区别，在网上找来了下面的图，PCA找到的是轴2，LDA找到的是轴1. LDA与PCA的目标不同，LDA希望降维后数据可以很容易的被分开。</p>
<p>近期也看了一篇Pacific Visualization 2016里利用LDA进行高维子空间的维度重建相关工作的论文【3】。</p>
<h2 id="非线性降维方法">非线性降维方法<a hidden class="heading-anchor" aria-hidden="true" href="#非线性降维方法">#</a></h2>
<h3 id="mds">MDS<a hidden class="heading-anchor" aria-hidden="true" href="#mds">#</a></h3>
<p>MDS中文名叫多维尺度分析，主要考虑的是成对样本间的相似性，主要思想是用成对样本的相似性来构建合适的低维空间，使得样本在低维空间的距离和高位空间中的距离尽可能的保持一致。非常合理但是有很对的思想。根据样本是否可计量，可分为Metric MDS和Nonmetric MDS。目标函数是每对低维空间中的欧式距离与高维空间中相似度差的平方和，最小化目标函数，用一些数值优化方法来得到最优解。</p>
<h2 id="isomap">Isomap<a hidden class="heading-anchor" aria-hidden="true" href="#isomap">#</a></h2>
<p>Isomap的理论框架是MDS，但是高维空间中的距离变了，不再是欧式距离了，而是用测地线距离代替了欧式距离。所谓的测地线，就是流形上加速度为零的曲线，等同于欧式空间中的直线。如下图所示，s曲面上蓝色和红色的两点，欧式距离很小，而实际上他们之间没有路，因此必须沿着曲面走完测地线，所以他们之间的距离很大。</p>
<h3 id="sne--t-sne">SNE &amp; t-SNE<a hidden class="heading-anchor" aria-hidden="true" href="#sne--t-sne">#</a></h3>
<p>这两种方法是Hinton组【4】提出的，可以说是state-of-art的方法。SNE想法与MDS类似，也是想将高维空间中的邻居信息保存到低维空间中，不过SNE的心比较小，它不是将所有点对直接的距离都保存下来，它只想将跟附近的邻居在一起，其他的离他本来就很远的点，根本不care。他的做法是将高维空间中点与点之间的欧式距离转化成条件概率，来代表相似度。低维空间中，也同样计算出这样一个概率。现在有了两个概率分布，怎么衡量他们之间的相似度呢？用KL散度！</p>
<p>KL散度是不平衡的，KL(p||q)与KL(q||p)不相对，这意味着不同种类的点对之间的距离错误在低维空间中没有得到同等对待。因此，symmetric SNE被提出来了。</p>
<p>t-SNE对于SNE改进是将高维空间中的欧氏距离换成了高斯分布，低维空间中，使用了heavy-tailed student t-distribution。带来了两个优点：</p>
<p>t-SNE的梯度强烈抵制不相似的点对在低维空间中被建模成距离很近。
尽管引入了不相似点对之间强烈的排斥，排斥力不会走向无穷。
t-SNE主要包括两个步骤：第一、t-SNE构建一个高维对象之间的概率分布，使得相似的对象有更高的概率被选择，而不相似的对象有较低的概率被选择。第二，t-SNE在低维空间里在构建这些点的概率分布，使得这两个概率分布之间尽可能的相似，同样也是来度量两个分布之间的相似性。</p>
<p>t-SNE可以将MNIST手写数字集几乎完全分开。在线尝试：http://scienceai.github.io/tsne-js/</p>
<p>t-SNE哪里都好，但是有一个致命的弱点，就是慢。不过，近期刚结束的WWW 2016上，华人学者唐健提出的LargeViz【5】，速度比t-SNE快了近30倍，想法很好！这种好的工作，比改改深度学习中网络的结构，调调参数，水一百篇论文更有意义！</p>
<h3 id="参考文献">参考文献<a hidden class="heading-anchor" aria-hidden="true" href="#参考文献">#</a></h3>
<p>【1】Nan Cao, Yu-Ru Lin, and David Gotz
，UnTangle Map: Visual Analysis of Probabilistic Multi-Label Data ，IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS, VOL. 22, NO. 2, FEBRUARY 2016</p>
<p>【2】Stef van den Elzen, Danny Holten, Jorik Blaas, Jarke J. van Wijk, Reducing Snapshots to Points: A Visual Analytics Approach to Dynamic Network Exploration , IEEE TVCG(VAST’ 15) VOL. 22 NO.1 2016</p>
<p>【3】Fangfang Zhou ，Juncai Li ，Wei Huang ， Ying Zhao ， Xiaoru Yuan ， Xing Liang ，Yang Shi，Dimension Reconstruction for Visual Exploration of Subspace Clusters in High-dimensional Data ， IEEE Pacific Visualization 2016</p>
<p>【4】Laurens van der Maaten and Geoffrey Hinton，Visualizing data using t-SNE, Laurens van der Maaten and Geoffrey Hintton, Journel of machine learning research, 2008.</p>
<p>【5】Jian Tang, Jingzhou Liu, Ming Zhang and Qiaozhu Mei , Visualizing Large-scale and High-dimensional Data , WWW 2016</p>



        
      </article>
    </div>

    
      <div class="meta article-card">
    <div class="row">
      <span class="label">



<svg xmlns='http://www.w3.org/2000/svg' class='ionicon' viewBox='0 0 512 512'><path d='M32 456a24 24 0 0024 24h400a24 24 0 0024-24V176H32zm320-244a4 4 0 014-4h40a4 4 0 014 4v40a4 4 0 01-4 4h-40a4 4 0 01-4-4zm0 80a4 4 0 014-4h40a4 4 0 014 4v40a4 4 0 01-4 4h-40a4 4 0 01-4-4zm-80-80a4 4 0 014-4h40a4 4 0 014 4v40a4 4 0 01-4 4h-40a4 4 0 01-4-4zm0 80a4 4 0 014-4h40a4 4 0 014 4v40a4 4 0 01-4 4h-40a4 4 0 01-4-4zm0 80a4 4 0 014-4h40a4 4 0 014 4v40a4 4 0 01-4 4h-40a4 4 0 01-4-4zm-80-80a4 4 0 014-4h40a4 4 0 014 4v40a4 4 0 01-4 4h-40a4 4 0 01-4-4zm0 80a4 4 0 014-4h40a4 4 0 014 4v40a4 4 0 01-4 4h-40a4 4 0 01-4-4zm-80-80a4 4 0 014-4h40a4 4 0 014 4v40a4 4 0 01-4 4h-40a4 4 0 01-4-4zm0 80a4 4 0 014-4h40a4 4 0 014 4v40a4 4 0 01-4 4h-40a4 4 0 01-4-4zM456 64h-55.92V32h-48v32H159.92V32h-48v32H56a23.8 23.8 0 00-24 23.77V144h448V87.77A23.8 23.8 0 00456 64z'/></svg>













Published At</span><time>2018-05-20 01:49 CST</time>
      
    </div>

    

    
      <div class="row social-share">
        <span class="label">















<svg xmlns='http://www.w3.org/2000/svg' class='ionicon' viewBox='0 0 512 512'><path d='M272 176v161h-32V176H92a12 12 0 00-12 12v280a12 12 0 0012 12h328a12 12 0 0012-12V188a12 12 0 00-12-12zM272 92.63l64 64L358.63 134 256 31.37 153.37 134 176 156.63l64-64V176h32V92.63z'/></svg>

Share with</span>
        
        
        <a
          target="_blank"
          title="share to reddit"
          rel="noopener noreferrer"
          aria-label="share 浅谈高维数据可视化中的降维方法 on reddit"
          href="https://reddit.com/submit?url=http%3a%2f%2flocalhost%3a1313%2fposts%2fp20180520014900%2f&title=%e6%b5%85%e8%b0%88%e9%ab%98%e7%bb%b4%e6%95%b0%e6%8d%ae%e5%8f%af%e8%a7%86%e5%8c%96%e4%b8%ad%e7%9a%84%e9%99%8d%e7%bb%b4%e6%96%b9%e6%b3%95">
          









<svg xmlns='http://www.w3.org/2000/svg' class='ionicon' viewBox='0 0 512 512' fill="currentColor" stroke="currentColor" stroke-width="10"><path d='M324 256a36 36 0 1036 36 36 36 0 00-36-36z'/><circle cx='188' cy='292' r='36' transform='rotate(-22.5 187.997 291.992)'/><path d='M496 253.77c0-31.19-25.14-56.56-56-56.56a55.72 55.72 0 00-35.61 12.86c-35-23.77-80.78-38.32-129.65-41.27l22-79 66.41 13.2c1.9 26.48 24 47.49 50.65 47.49 28 0 50.78-23 50.78-51.21S441 48 413 48c-19.53 0-36.31 11.19-44.85 28.77l-90-17.89-31.1 109.52-4.63.13c-50.63 2.21-98.34 16.93-134.77 41.53A55.38 55.38 0 0072 197.21c-30.89 0-56 25.37-56 56.56a56.43 56.43 0 0028.11 49.06 98.65 98.65 0 00-.89 13.34c.11 39.74 22.49 77 63 105C146.36 448.77 199.51 464 256 464s109.76-15.23 149.83-42.89c40.53-28 62.85-65.27 62.85-105.06a109.32 109.32 0 00-.84-13.3A56.32 56.32 0 00496 253.77zM414 75a24 24 0 11-24 24 24 24 0 0124-24zM42.72 253.77a29.6 29.6 0 0129.42-29.71 29 29 0 0113.62 3.43c-15.5 14.41-26.93 30.41-34.07 47.68a30.23 30.23 0 01-8.97-21.4zM390.82 399c-35.74 24.59-83.6 38.14-134.77 38.14S157 423.61 121.29 399c-33-22.79-51.24-52.26-51.24-83A78.5 78.5 0 0175 288.72c5.68-15.74 16.16-30.48 31.15-43.79a155.17 155.17 0 0114.76-11.53l.3-.21.24-.17c35.72-24.52 83.52-38 134.61-38s98.9 13.51 134.62 38l.23.17.34.25A156.57 156.57 0 01406 244.92c15 13.32 25.48 28.05 31.16 43.81a85.44 85.44 0 014.31 17.67 77.29 77.29 0 01.6 9.65c-.01 30.72-18.21 60.19-51.25 82.95zm69.6-123.92c-7.13-17.28-18.56-33.29-34.07-47.72A29.09 29.09 0 01440 224a29.59 29.59 0 0129.41 29.71 30.07 30.07 0 01-8.99 21.39z'/><path d='M323.23 362.22c-.25.25-25.56 26.07-67.15 26.27-42-.2-66.28-25.23-67.31-26.27a4.14 4.14 0 00-5.83 0l-13.7 13.47a4.15 4.15 0 000 5.89c3.4 3.4 34.7 34.23 86.78 34.45 51.94-.22 83.38-31.05 86.78-34.45a4.16 4.16 0 000-5.9l-13.71-13.47a4.13 4.13 0 00-5.81 0z'/></svg>








        </a>
        <a
          target="_blank"
          title="share to twitter"
          rel="noopener noreferrer"
          aria-label="share 浅谈高维数据可视化中的降维方法 on twitter"
          href="https://twitter.com/intent/tweet/?text=%e6%b5%85%e8%b0%88%e9%ab%98%e7%bb%b4%e6%95%b0%e6%8d%ae%e5%8f%af%e8%a7%86%e5%8c%96%e4%b8%ad%e7%9a%84%e9%99%8d%e7%bb%b4%e6%96%b9%e6%b3%95&amp;url=http%3a%2f%2flocalhost%3a1313%2fposts%2fp20180520014900%2f&amp;hashtags=">
          










<svg class="ionicon" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" style="fill:none;" stroke="currentColor" stroke-width="2"><path d="M23 3a10.9 10.9 0 0 1-3.14 1.53 4.48 4.48 0 0 0-7.86 3v1A10.66 10.66 0 0 1 3 4s-4 9 5 13a11.64 11.64 0 0 1-7 2c9 5 20 0 20-11.5a4.5 4.5 0 0 0-.08-.83A7.72 7.72 0 0 0 23 3z"></path></svg>







        </a>
        <a
          target="_blank"
          title="share to facebook"
          rel="noopener noreferrer"
          aria-label="share 浅谈高维数据可视化中的降维方法 on facebook"
          href="https://facebook.com/sharer/sharer.php?u=http%3a%2f%2flocalhost%3a1313%2fposts%2fp20180520014900%2f">
          








<svg xmlns="http://www.w3.org/2000/svg" class="ionicon" viewBox="0 0 24 24" style="fill:none;" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-facebook"><path d="M18 2h-3a5 5 0 0 0-5 5v3H7v4h3v8h4v-8h3l1-4h-4V7a1 1 0 0 1 1-1h3z"></path></svg>









        </a>
      </div>
    

    
</div>

    

    

  </div>
</main>

  </main>
  <footer>
    <footer id="footer">
  <div class="container has-padding is-flex">
    <ul class="links">
      
      <li>
        </li>
      <li>
        <a
          rel="nofollow"
          target="_blank"
          href="https://github.com/wayjam/hugo-theme-fluency"
          title="using Hugo theme fluency">
          Theme Fluency
        </a>
      </li>
      <li>
        <a rel="nofollow" target="_blank" href="https://gohugo.io" title="Built with hugo">Built with Hugo</a>
      </li>
    </ul>
    <div class="copyright">
       &copy; 2025 Combine Art and Sciences
      
    </div>
  </div>
</footer>

<script>
    window.FluencyCopyIcon = '\n\n\n\n\n\n\n\u003csvg xmlns=\u0027http:\/\/www.w3.org\/2000\/svg\u0027 class=\u0027ionicon\u0027 viewBox=\u00270 0 512 512\u0027\u003e\u003crect x=\u0027128\u0027 y=\u0027128\u0027 width=\u0027336\u0027 height=\u0027336\u0027 rx=\u002757\u0027 ry=\u002757\u0027 stroke-linejoin=\u0027round\u0027 class=\u0027ionicon-fill-none ionicon-stroke-width\u0027\/\u003e\u003cpath d=\u0027M383.5 128l.5-24a56.16 56.16 0 00-56-56H112a64.19 64.19 0 00-64 64v216a56.16 56.16 0 0056 56h24\u0027 stroke-linecap=\u0027round\u0027 stroke-linejoin=\u0027round\u0027 class=\u0027ionicon-fill-none ionicon-stroke-width\u0027\/\u003e\u003c\/svg\u003e\n\n\n\n\n\n\n\n\n\n\n'
</script>


<script defer src="http://localhost:1313/js/main.min.15ea6de828b83519cdc1bc66872563a50cd5e59b4b1cfc6f31019951922b2e78.js" integrity="sha256-Fept6Ci4NRnNwbxmhyVjpQzV5ZtLHPxvMQGZUZIrLng=" crossorigin="anonymous" async></script>


    <link
  rel="stylesheet"
  href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css"
  integrity="sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X"
  crossorigin="anonymous"
/>


<script
  defer
  src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.js"
  integrity="sha384-g7c+Jr9ZivxKLnZTDUhnkOnsh30B4H0rpLUpJ4jAIKs4fnJI+sEnkvrMWph2EDg4"
  crossorigin="anonymous"
></script>


<script
  defer
  src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/contrib/auto-render.min.js"
  integrity="sha384-mll67QQFJfxn0IYznZYonOWZ644AWYC+Pt2cHqMaRhXVrursRwvLnLaebdGIlYNa"
  crossorigin="anonymous"
  onload="renderMathInElement(document.body);"
></script>



<noscript>
<style type=text/css>#theme-selector-button{display:none}</style>
</noscript>




  </footer>
</body>
</html>